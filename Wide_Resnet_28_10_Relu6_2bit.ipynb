{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyOCAW97sVZak9tywtNF+bIH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carba6/deeplearning/blob/main/Wide_Resnet_28_10_Relu6_2bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ccdb04N-Aq2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a70af3c-9f81-40d3-a57d-2a62ba35f732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "| Wide-Resnet 10x3\n",
            "Is GPU available? True\n",
            "Current device: 0\n",
            "Epoch: 1, Loss: 2.1574, Validation Accuracy: 19.38%\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-5022204a2bd6>\u001b[0m in \u001b[0;36m<cell line: 231>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-5022204a2bd6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mquantized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantized_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {test_accuracy * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-5022204a2bd6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, dataloader, criterion, device)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/wide_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/ao/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    467\u001b[0m             input = F.pad(input, _reversed_padding_repeated_twice,\n\u001b[1;32m    468\u001b[0m                           mode=self.padding_mode)\n\u001b[0;32m--> 469\u001b[0;31m         return ops.quantized.conv2d(\n\u001b[0m\u001b[1;32m    470\u001b[0m             input, self._packed_params, self.scale, self.zero_point)\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1555 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Conv.cpp:418 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:30 [backend fallback]\nAutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:34 [backend fallback]\nAutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:42 [backend fallback]\nAutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:46 [backend fallback]\nAutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:54 [backend fallback]\nAutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:38 [backend fallback]\nAutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:50 [backend fallback]\nAutogradMeta: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:58 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from wide_resnet import Wide_ResNet\n",
        "import torch.quantization as quantization\n",
        "from torch.quantization import FakeQuantize, default_qconfig, QuantStub, DeQuantStub\n",
        "from torch.quantization.qconfig import QConfig\n",
        "# from torch.quantization import MinMaxObserver\n",
        "\n",
        "\n",
        "from torch.quantization import HistogramObserver\n",
        "\n",
        "class CustomHistogramObserverActivation(HistogramObserver):\n",
        "    def __init__(self, num_bits, **kwargs):\n",
        "        self.num_bits = num_bits\n",
        "        super(CustomHistogramObserverActivation, self).__init__(**kwargs)\n",
        "\n",
        "    def calculate_qparams(self):\n",
        "        min_val, max_val = self.min_val, self.max_val\n",
        "\n",
        "        scale = (max_val - min_val) / (2 ** self.num_bits - 1)\n",
        "        zero_point = 0\n",
        "        return torch.tensor([scale]), torch.tensor([zero_point], dtype=torch.int64)\n",
        "\n",
        "class CustomHistogramObserverWeight(HistogramObserver):\n",
        "    def __init__(self, num_bits, **kwargs):\n",
        "        self.num_bits = num_bits\n",
        "        super(CustomHistogramObserverWeight, self).__init__(**kwargs)\n",
        "\n",
        "    def calculate_qparams(self):\n",
        "        min_val, max_val = self.min_val, self.max_val\n",
        "\n",
        "        scale = (max_val - min_val) / (2 ** self.num_bits - 1)\n",
        "        zero_point = int(-min_val / scale)\n",
        "        return torch.tensor([scale]), torch.tensor([zero_point], dtype=torch.int64)\n",
        "\n",
        "def custom_qconfig(num_bits):\n",
        "    return QConfig(\n",
        "        activation=FakeQuantize.with_args(observer=CustomHistogramObserverActivation, num_bits=num_bits, dtype=torch.quint8),\n",
        "        weight=FakeQuantize.with_args(observer=CustomHistogramObserverWeight, num_bits=num_bits, dtype=torch.qint8),\n",
        "    )\n",
        "# class CustomMinMaxObserver(MinMaxObserver):\n",
        "#     def __init__(self, num_bits, **kwargs):\n",
        "#         super().__init__(**kwargs)\n",
        "#         self.num_bits = num_bits\n",
        "#         self.qmin = 0\n",
        "#         self.qmax = 2 ** num_bits - 1\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         self.min_val = torch.min(x)\n",
        "#         self.max_val = torch.max(x)\n",
        "\n",
        "#         scale, zero_point = self.calculate_qparams()\n",
        "#         new_min = torch.min(torch.tensor([self.min_val, scale * (self.qmin - zero_point)]))\n",
        "#         new_max = torch.max(torch.tensor([self.max_val, scale * (self.qmax - zero_point)]))\n",
        "\n",
        "#         self.min_val = torch.min(new_min, self.min_val)\n",
        "#         self.max_val = torch.max(new_max, self.max_val)\n",
        "#         return x\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    batch_size = 128\n",
        "    learning_rate = 0.1\n",
        "    epochs = 1\n",
        "    weight_decay = 0.0005\n",
        "    momentum = 0.9\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_bits = 5\n",
        "\n",
        "    # 数据预处理\n",
        "    transform = transforms.Compose([\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # 加载CIFAR-10数据集\n",
        "    full_train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "    # 将训练数据集分为训练集、验证集和测试集\n",
        "    train_ratio = 0.7\n",
        "    validation_ratio = 0.1\n",
        "    test_ratio = 0.2\n",
        "    num_train_samples = int(len(full_train_dataset) * train_ratio)\n",
        "    num_validation_samples = int(len(full_train_dataset) * validation_ratio)\n",
        "    num_test_samples = len(full_train_dataset) - num_train_samples - num_validation_samples\n",
        "\n",
        "    train_dataset, validation_dataset, test_dataset_from_train = random_split(full_train_dataset, [num_train_samples, num_validation_samples, num_test_samples])\n",
        "    test_dataset = torch.utils.data.ConcatDataset([test_dataset, test_dataset_from_train])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # 创建Wide ResNet模型\n",
        "    model = Wide_ResNet(depth=10, widen_factor=3, num_classes=10, dropout_rate=0.3).to(device)\n",
        "\n",
        "    # 创建num_bits位量化配置\n",
        "    # num_bit_qconfig = QConfig(\n",
        "    #     activation=FakeQuantize.with_args(observer=CustomMinMaxObserver, dtype=torch.quint8, qscheme=torch.per_tensor_affine, num_bits=num_bits),\n",
        "    #     weight=FakeQuantize.with_args(observer=CustomMinMaxObserver, dtype=torch.qint8, qscheme=torch.per_tensor_affine, num_bits=num_bits)\n",
        "    # )\n",
        "\n",
        "    # 准备QAT\n",
        "    model.qconfig = custom_qconfig(num_bits)\n",
        "    qat_model = quantization.prepare_qat(model, inplace=False).to(device)\n",
        "\n",
        "    # 设置损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(qat_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    # 设置学习率调度器\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120], gamma=0.1)\n",
        "\n",
        "    # 训练和测试函数\n",
        "    def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        return running_loss / len(dataloader)\n",
        "\n",
        "\n",
        "    def test(model, dataloader, criterion, device):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "        return correct / total\n",
        "\n",
        "\n",
        "    # 训练循环\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_epoch(qat_model, train_loader, criterion, optimizer, device)\n",
        "        validation_accuracy = test(qat_model, validation_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch: {epoch}, Loss: {train_loss:.4f}, Validation Accuracy: {validation_accuracy * 100:.2f}%\")\n",
        "\n",
        "        # 每隔一定的epoch数量（如5个），冻结统计数据并执行一次量化\n",
        "        if epoch % 5 == 4:\n",
        "            qat_model.apply(quantization.disable_observer)\n",
        "            qat_model.apply(quantization.enable_fake_quant)\n",
        "\n",
        "        # 每隔一定的epoch数量（如10个），解冻统计数据\n",
        "        if epoch % 10 == 9:\n",
        "            qat_model.apply(quantization.enable_observer)\n",
        "    print(1)\n",
        "    # 量化训练完成后，将QAT模型转换为量化模型\n",
        "    def calibrate(model, loader, device):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, _ in loader:\n",
        "                images = images.to(device)\n",
        "                _ = model(images)\n",
        "    qat_model.to('cpu') \n",
        "    calibrate(qat_model, train_loader, 'cpu')           \n",
        "    quantized_model = quantization.convert(qat_model, inplace=False)\n",
        "\n",
        "    test_accuracy = test(quantized_model, test_loader, criterion, 'cpu')\n",
        "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "    print(2)\n",
        "    def check_quantization(model):\n",
        "        quantized = True\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
        "                if not isinstance(module, (torch.quantization.QuantizedConv2d, torch.quantization.QuantizedLinear)):\n",
        "                    quantized = False\n",
        "                    print(f\"{name} is not quantized\")\n",
        "        return quantized\n",
        "\n",
        "    is_quantized = check_quantization(quantized_model)\n",
        "    if is_quantized:\n",
        "        print(\"The model has been successfully quantized.\")\n",
        "    else:\n",
        "        print(\"The model has not been fully quantized.\")\n",
        "    # 保存最终量化模型\n",
        "    quantized_model_path = f\"WRN_Relu6_{num_bits}bit.pth\"\n",
        "    # torch.save(quantized_model.state_dict(), quantized_model_path)\n",
        "    print(f\"{num_bits}-bit Relu6 Quantized WRN model saved as {quantized_model_path}\")\n",
        "\n",
        "    t_device = torch.device(\"cuda\")\n",
        "    t_model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.3).to(t_device)\n",
        "\n",
        "    def test_quantized(model, dataloader, device):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                # 量化输入数据\n",
        "                targets = targets.to('cpu')\n",
        "                inputs = inputs.to('cpu')\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "        return correct / total\n",
        "    # 准备QAT\n",
        "    t_model.qconfig = num_bit_qconfig\n",
        "    t_qat_model = quantization.prepare_qat(t_model, inplace=False).to(t_device)    \n",
        "    t_quantized_model = quantization.convert(t_qat_model, inplace=False)\n",
        "    state_dict = torch.load(f\"WRN_Relu6_{num_bits}bit.pth\", map_location='cpu')\n",
        "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "    t_quantized_model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "    test_accuracy = test_quantized(t_quantized_model, test_loader, t_device)\n",
        "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qfrom google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "bXBG7RPXMisE",
        "outputId": "7ea2a8f8-6df4-44f2-8c5f-9a810213549d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp WRN_Relu6_2bit.pth /content/drive/MyDrive/model"
      ],
      "metadata": {
        "id": "gVx9jnoDNblC"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}