{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyMnoUQEOD1vMj6P9lNnv0I2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carba6/deeplearning/blob/main/%E2%80%9CWide_Resnet_28_10_Relu6_5bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAfm0oQqbuz-",
        "outputId": "26cf1328-ca73-4c21-e63c-cae6e2ea7082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "| Wide-Resnet 28x10\n",
            "Is GPU available? True\n",
            "Current device: 0\n",
            "Epoch: 1, Loss: 1.7940, Validation Accuracy: 41.86%\n",
            "8-bit Relu6 Quantized WRN model saved as WRN_Relu6_8bit.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from WRN_Relu import Wide_ResNet\n",
        "import torch.quantization as quantization\n",
        "from torch.quantization import FakeQuantize, default_qconfig, QuantStub, DeQuantStub\n",
        "from torch.quantization.qconfig import QConfig\n",
        "from torch.quantization import MinMaxObserver\n",
        "\n",
        "class CustomMinMaxObserver(MinMaxObserver):\n",
        "    def __init__(self, num_bits, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_bits = num_bits\n",
        "        self.qmin = 0\n",
        "        self.qmax = 2 ** num_bits - 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.min_val = torch.min(x)\n",
        "        self.max_val = torch.max(x)\n",
        "\n",
        "        scale, zero_point = self.calculate_qparams()\n",
        "        new_min = torch.min(torch.tensor([self.min_val, scale * (self.qmin - zero_point)]))\n",
        "        new_max = torch.max(torch.tensor([self.max_val, scale * (self.qmax - zero_point)]))\n",
        "\n",
        "        self.min_val = torch.min(new_min, self.min_val)\n",
        "        self.max_val = torch.max(new_max, self.max_val)\n",
        "        return x\n",
        "\n",
        "def main():\n",
        "\n",
        "    batch_size = 128\n",
        "    learning_rate = 0.1\n",
        "    epochs = 1\n",
        "    weight_decay = 0.0005\n",
        "    momentum = 0.9\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_bits = 8\n",
        "\n",
        "    # 数据预处理\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # 加载CIFAR-10数据集\n",
        "    full_train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "    # 将训练数据集分为训练集、验证集和测试集\n",
        "    train_ratio = 0.7\n",
        "    validation_ratio = 0.1\n",
        "    test_ratio = 0.2\n",
        "    num_train_samples = int(len(full_train_dataset) * train_ratio)\n",
        "    num_validation_samples = int(len(full_train_dataset) * validation_ratio)\n",
        "    num_test_samples = len(full_train_dataset) - num_train_samples - num_validation_samples\n",
        "\n",
        "    train_dataset, validation_dataset, test_dataset_from_train = random_split(full_train_dataset, [num_train_samples, num_validation_samples, num_test_samples])\n",
        "    test_dataset = torch.utils.data.ConcatDataset([test_dataset, test_dataset_from_train])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    # 创建Wide ResNet模型\n",
        "    model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.3).to(device)\n",
        "\n",
        "    # 创建5位量化配置\n",
        "    five_bit_qconfig = QConfig(\n",
        "        activation=FakeQuantize.with_args(observer=CustomMinMaxObserver, dtype=torch.quint8, qscheme=torch.per_tensor_affine, num_bits=5),\n",
        "        weight=FakeQuantize.with_args(observer=CustomMinMaxObserver, dtype=torch.qint8, qscheme=torch.per_tensor_affine, num_bits=5)\n",
        "    )\n",
        "\n",
        "    # 准备QAT\n",
        "    model.qconfig = five_bit_qconfig\n",
        "    qat_model = quantization.prepare_qat(model, inplace=False).to(device)\n",
        "\n",
        "    # 设置损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(qat_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    # 设置学习率调度器\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120], gamma=0.1)\n",
        "\n",
        "    # 训练和测试函数\n",
        "    def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        return running_loss / len(dataloader)\n",
        "\n",
        "\n",
        "    def test(model, dataloader, criterion, device):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "        return correct / total\n",
        "\n",
        "\n",
        "    # 训练循环\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_epoch(qat_model, train_loader, criterion, optimizer, device)\n",
        "        validation_accuracy = test(qat_model, validation_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch: {epoch}, Loss: {train_loss:.4f}, Validation Accuracy: {validation_accuracy * 100:.2f}%\")\n",
        "\n",
        "        # 每隔一定的epoch数量（如5个），冻结统计数据并执行一次量化\n",
        "        if epoch % 5 == 4:\n",
        "            qat_model.apply(quantization.disable_observer)\n",
        "            qat_model.apply(quantization.enable_fake_quant)\n",
        "\n",
        "        # 每隔一定的epoch数量（如10个），解冻统计数据\n",
        "        if epoch % 10 == 9:\n",
        "            qat_model.apply(quantization.enable_observer)\n",
        "\n",
        "    # 量化训练完成后，将QAT模型转换为量化模型\n",
        "    quantized_model = quantization.convert(qat_model, inplace=False)\n",
        "  \n",
        "    # 最终在测试集上进行评估\n",
        "    # quantized_model = quantized_model.to(\"cpu\")\n",
        "    # test_accuracy = test(quantized_model, test_loader, criterion, device)\n",
        "    # print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 保存最终量化模型\n",
        "    quantized_model_path = f\"WRN_Relu6_{num_bits}bit.pth\"\n",
        "    torch.save(quantized_model.state_dict(), quantized_model_path)\n",
        "    print(f\"{num_bits}-bit Relu6 Quantized WRN model saved as {quantized_model_path}\")\n",
        "\n",
        "    # # 创建与保存模型具有相同结构的新模型\n",
        "    # q_model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.0)\n",
        "\n",
        "    # # 加载保存的模型状态字典\n",
        "    # quantized_model_path = \"WRN_Relu6_5bit.pth\"\n",
        "    # state_dict_quantized = torch.load(quantized_model_path)\n",
        "\n",
        "    # # 创建一个新的状态字典，用于存储浮点格式的权重\n",
        "    # state_dict_float = {}\n",
        "\n",
        "    # # 将量化权重转换为浮点格式并存储在新状态字典中\n",
        "    # for key, value in state_dict_quantized.items():\n",
        "    #     if \"scale\" not in key and \"zero_point\" not in key:\n",
        "    #         state_dict_float[key] = value.dequantize()\n",
        "\n",
        "    # # 将加载的状态字典应用到新模型\n",
        "    # q_model.load_state_dict(state_dict_float)\n",
        "\n",
        "    # # 将新模型转移到所需的设备\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # q_model.to(device)\n",
        "\n",
        "    # test_accuracy = test(q_model, test_loader, criterion, device)\n",
        "    # print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # def load_quantized_model(model_path, device):\n",
        "    #     model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.0).to(device)\n",
        "    #     model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "    #     quantized_model = torch.quantization.prepare(model, inplace=False)\n",
        "    #     quantized_model.load_state_dict(torch.load(model_path))\n",
        "    #     quantized_model = torch.quantization.convert(quantized_model, inplace=False)\n",
        "    #     return quantized_model\n",
        "\n",
        "    # # 加载量化后的模型\n",
        "    # num_bits = 5\n",
        "    # quantized_model_path = f\"WRN_Relu6_{num_bits}bit.pth\"\n",
        "    # quantized_model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.3).to(device)\n",
        "    # quantized_model.load_state_dict(torch.load(quantized_model_path, map_location=device))\n",
        "\n",
        "    # # 重新定义MinMaxObserver并进行初始化\n",
        "    # observer = CustomMinMaxObserver(num_bits, dtype=torch.quint8, qscheme=torch.per_tensor_affine)\n",
        "    # quantized_model.conv1.activation_post_process = observer\n",
        "\n",
        "    # for module in quantized_model.modules():\n",
        "    #     if isinstance(module, nn.BatchNorm2d):\n",
        "    #         module.activation_post_process = observer\n",
        "\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # quantized_model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.0).to(device)\n",
        "\n",
        "    # # quantized_model_path = \"WRN_Relu6_5bit.pth\"\n",
        "    # # device = torch.device(\"cpu\")\n",
        "    # # quantized_model = load_quantized_model(quantized_model_path, device)\n",
        "\n",
        "    # # 使用加载的量化模型进行验证\n",
        "    # test_accuracy = test(quantized_model, test_loader, device)\n",
        "    # print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "    # # 创建Wide ResNet模型\n",
        "    # q_model = Wide_ResNet(depth=28, widen_factor=10, num_classes=10, dropout_rate=0.0)\n",
        "\n",
        "    # # 加载保存的量化模型\n",
        "    # quantized_model_path = \"WRN_Relu6_5bit.pth\"\n",
        "    # state_dict_quantized = torch.load(quantized_model_path)\n",
        "\n",
        "    # # 创建一个新的状态字典，用于存储浮点格式的权重\n",
        "    # state_dict_float = {}\n",
        "\n",
        "    # # 将量化权重转换为浮点格式并存储在新状态字典中\n",
        "    # # for key, value in state_dict_quantized.items():\n",
        "    # #     if \"scale\" not in key and \"zero_point\" not in key:\n",
        "    # #         state_dict_float[key] = value.to('cpu:qnnpack').int_repr().float()\n",
        "\n",
        "    # # 将加载的状态字典应用到新模型\n",
        "    # q_model.load_state_dict(state_dict_float)\n",
        "\n",
        "    # # 打印模型结构\n",
        "    # print(q_model)\n",
        "\n",
        "\n",
        "    # # 打印模型结构\n",
        "    # print(q_model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Carba6\"\n",
        "!git config --global user.email \"1102046255@qq.com\"\n",
        "!git clone https://github.com/Carba6/deeplearning.git\n",
        "\n",
        "%cd /content/deeplearning\n",
        "\n",
        "!pwd\n",
        "!cp /content/WRN_Relu.py /content/deeplearning\n",
        "!git add WRN_Relu.py\n",
        "!git commit -m \"Add WRN_Relu.py\"\n",
        "!git remote set-url origin https://Carba6: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@github.com/Carba6/deeplearning.git\n",
        "!git push -f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdytA4qbuuU9",
        "outputId": "3b0190bc-c20b-4fe5-f1cb-55a19b441808"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deeplearning' already exists and is not an empty directory.\n",
            "/content/deeplearning\n",
            "/content/deeplearning\n",
            "[main f51c961] Add WRN_Relu.py\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 12 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 292 bytes | 292.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Carba6/deeplearning.git\n",
            "   0f31992..f51c961  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "hhm94RTjdvWo",
        "outputId": "a305fb1b-128b-4227-d684-7b10f187832f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Zhaogui/modules.git"
      ],
      "metadata": {
        "id": "nd3UZPTr77UA",
        "outputId": "60dbc07a-70b0-4315-e553-416b17b3ac03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'modules'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ]
}