{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJc8+hXuDe7/jse9X6oykR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carba6/deeplearning/blob/main/WRN_28_10_Relu6_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxfGi0iKZna",
        "outputId": "1a909faa-ca1a-4564-b3d7-eb79760a755b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE1KIdYtEFag",
        "outputId": "39d2687e-3031-4a46-d0b5-46310eaeb7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is GPU available? True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Creat WRN_full_precision successfully!\n",
            "Epoch: 1, Loss: 1.7819, Validation Accuracy: 40.52%\n",
            "Epoch: 2, Loss: 1.3196, Validation Accuracy: 47.50%\n",
            "Epoch: 3, Loss: 1.0553, Validation Accuracy: 54.16%\n",
            "Epoch: 4, Loss: 0.9284, Validation Accuracy: 31.32%\n",
            "Epoch: 5, Loss: 0.8315, Validation Accuracy: 51.82%\n",
            "Epoch: 6, Loss: 0.7451, Validation Accuracy: 62.28%\n",
            "Epoch: 7, Loss: 0.6789, Validation Accuracy: 51.76%\n",
            "Epoch: 8, Loss: 0.6315, Validation Accuracy: 63.30%\n",
            "Epoch: 9, Loss: 0.5778, Validation Accuracy: 64.98%\n",
            "Epoch: 10, Loss: 0.5562, Validation Accuracy: 54.38%\n",
            "Epoch: 11, Loss: 0.5312, Validation Accuracy: 68.40%\n",
            "Epoch: 12, Loss: 0.5028, Validation Accuracy: 60.98%\n",
            "Epoch: 13, Loss: 0.4923, Validation Accuracy: 75.28%\n",
            "Epoch: 14, Loss: 0.4756, Validation Accuracy: 75.44%\n",
            "Epoch: 15, Loss: 0.4574, Validation Accuracy: 72.20%\n",
            "Epoch: 16, Loss: 0.4511, Validation Accuracy: 71.62%\n",
            "Epoch: 17, Loss: 0.4432, Validation Accuracy: 74.64%\n",
            "Epoch: 18, Loss: 0.4303, Validation Accuracy: 77.58%\n",
            "Epoch: 19, Loss: 0.4181, Validation Accuracy: 78.30%\n",
            "Epoch: 20, Loss: 0.4069, Validation Accuracy: 76.24%\n",
            "Epoch: 21, Loss: 0.4021, Validation Accuracy: 77.74%\n",
            "Epoch: 22, Loss: 0.3911, Validation Accuracy: 81.30%\n",
            "Epoch: 23, Loss: 0.3835, Validation Accuracy: 83.22%\n",
            "Epoch: 24, Loss: 0.3752, Validation Accuracy: 80.00%\n",
            "Epoch: 25, Loss: 0.3691, Validation Accuracy: 80.56%\n",
            "Epoch: 26, Loss: 0.3712, Validation Accuracy: 83.28%\n",
            "Epoch: 27, Loss: 0.3709, Validation Accuracy: 78.42%\n",
            "Epoch: 28, Loss: 0.3549, Validation Accuracy: 78.60%\n",
            "Epoch: 29, Loss: 0.3632, Validation Accuracy: 82.60%\n",
            "Epoch: 30, Loss: 0.3473, Validation Accuracy: 81.98%\n",
            "Epoch: 31, Loss: 0.3498, Validation Accuracy: 79.02%\n",
            "Epoch: 32, Loss: 0.3456, Validation Accuracy: 81.10%\n",
            "Epoch: 33, Loss: 0.3517, Validation Accuracy: 79.72%\n",
            "Epoch: 34, Loss: 0.3342, Validation Accuracy: 77.24%\n",
            "Epoch: 35, Loss: 0.3294, Validation Accuracy: 81.46%\n",
            "Epoch: 36, Loss: 0.3404, Validation Accuracy: 81.40%\n",
            "Epoch: 37, Loss: 0.3256, Validation Accuracy: 79.56%\n",
            "Epoch: 38, Loss: 0.3291, Validation Accuracy: 78.30%\n",
            "Epoch: 39, Loss: 0.3218, Validation Accuracy: 78.36%\n",
            "Epoch: 40, Loss: 0.3264, Validation Accuracy: 83.26%\n",
            "Epoch: 41, Loss: 0.3235, Validation Accuracy: 84.04%\n",
            "Epoch: 42, Loss: 0.3215, Validation Accuracy: 83.18%\n",
            "Epoch: 43, Loss: 0.3124, Validation Accuracy: 79.08%\n",
            "Epoch: 44, Loss: 0.3153, Validation Accuracy: 82.62%\n",
            "Epoch: 45, Loss: 0.3175, Validation Accuracy: 84.74%\n",
            "Epoch: 46, Loss: 0.3170, Validation Accuracy: 81.02%\n",
            "Epoch: 47, Loss: 0.3183, Validation Accuracy: 81.94%\n",
            "Epoch: 48, Loss: 0.3125, Validation Accuracy: 79.82%\n",
            "Epoch: 49, Loss: 0.3123, Validation Accuracy: 84.56%\n",
            "Epoch: 50, Loss: 0.3064, Validation Accuracy: 83.78%\n",
            "Epoch: 51, Loss: 0.3091, Validation Accuracy: 85.26%\n",
            "Epoch: 52, Loss: 0.3038, Validation Accuracy: 83.00%\n",
            "Epoch: 53, Loss: 0.3076, Validation Accuracy: 76.58%\n",
            "Epoch: 54, Loss: 0.2994, Validation Accuracy: 79.58%\n",
            "Epoch: 55, Loss: 0.3091, Validation Accuracy: 82.42%\n",
            "Epoch: 56, Loss: 0.3072, Validation Accuracy: 81.72%\n",
            "Epoch: 57, Loss: 0.3018, Validation Accuracy: 81.76%\n",
            "Epoch: 58, Loss: 0.3055, Validation Accuracy: 85.18%\n",
            "Epoch: 59, Loss: 0.3048, Validation Accuracy: 71.26%\n",
            "Epoch: 60, Loss: 0.3086, Validation Accuracy: 81.34%\n",
            "Epoch: 61, Loss: 0.1562, Validation Accuracy: 91.70%\n",
            "Epoch: 62, Loss: 0.1030, Validation Accuracy: 91.90%\n",
            "Epoch: 63, Loss: 0.0843, Validation Accuracy: 92.46%\n",
            "Epoch: 64, Loss: 0.0729, Validation Accuracy: 93.06%\n",
            "Epoch: 65, Loss: 0.0628, Validation Accuracy: 93.26%\n",
            "Epoch: 66, Loss: 0.0569, Validation Accuracy: 92.64%\n",
            "Epoch: 67, Loss: 0.0488, Validation Accuracy: 93.20%\n",
            "Epoch: 68, Loss: 0.0429, Validation Accuracy: 93.34%\n",
            "Epoch: 69, Loss: 0.0396, Validation Accuracy: 93.26%\n",
            "Epoch: 70, Loss: 0.0375, Validation Accuracy: 93.08%\n",
            "Epoch: 71, Loss: 0.0333, Validation Accuracy: 93.18%\n",
            "Epoch: 72, Loss: 0.0292, Validation Accuracy: 92.96%\n",
            "Epoch: 73, Loss: 0.0266, Validation Accuracy: 93.14%\n",
            "Epoch: 74, Loss: 0.0254, Validation Accuracy: 93.44%\n",
            "Epoch: 75, Loss: 0.0238, Validation Accuracy: 93.04%\n",
            "Epoch: 76, Loss: 0.0227, Validation Accuracy: 93.20%\n",
            "Epoch: 77, Loss: 0.0196, Validation Accuracy: 92.94%\n",
            "Epoch: 78, Loss: 0.0195, Validation Accuracy: 93.22%\n",
            "Epoch: 79, Loss: 0.0190, Validation Accuracy: 93.48%\n",
            "Epoch: 80, Loss: 0.0180, Validation Accuracy: 93.34%\n",
            "Epoch: 81, Loss: 0.0174, Validation Accuracy: 93.58%\n",
            "Epoch: 82, Loss: 0.0166, Validation Accuracy: 93.02%\n",
            "Epoch: 83, Loss: 0.0181, Validation Accuracy: 93.02%\n",
            "Epoch: 84, Loss: 0.0176, Validation Accuracy: 93.26%\n",
            "Epoch: 85, Loss: 0.0172, Validation Accuracy: 92.74%\n",
            "Epoch: 86, Loss: 0.0146, Validation Accuracy: 92.64%\n",
            "Epoch: 87, Loss: 0.0175, Validation Accuracy: 92.72%\n",
            "Epoch: 88, Loss: 0.0169, Validation Accuracy: 93.16%\n",
            "Epoch: 89, Loss: 0.0181, Validation Accuracy: 92.52%\n",
            "Epoch: 90, Loss: 0.0178, Validation Accuracy: 92.80%\n",
            "Epoch: 91, Loss: 0.0188, Validation Accuracy: 92.20%\n",
            "Epoch: 92, Loss: 0.0149, Validation Accuracy: 92.98%\n",
            "Epoch: 93, Loss: 0.0170, Validation Accuracy: 93.34%\n",
            "Epoch: 94, Loss: 0.0170, Validation Accuracy: 93.24%\n",
            "Epoch: 95, Loss: 0.0147, Validation Accuracy: 93.02%\n",
            "Epoch: 96, Loss: 0.0178, Validation Accuracy: 93.00%\n",
            "Epoch: 97, Loss: 0.0184, Validation Accuracy: 92.82%\n",
            "Epoch: 98, Loss: 0.0171, Validation Accuracy: 93.42%\n",
            "Epoch: 99, Loss: 0.0191, Validation Accuracy: 92.82%\n",
            "Epoch: 100, Loss: 0.0191, Validation Accuracy: 92.70%\n",
            "full_precision model Test Accuracy: 92.50%\n",
            "full_precision WRN_28_10_Relu6 model saved as WRN_full_precision.pth\n",
            "copy full_precision model to google drive successfully!\n",
            "Creat WRN_quant successfully!\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Check if 1 bits model quantize successfully\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Layer conv1 is quantized.\n",
            "Layer layer1.0.conv1 is quantized.\n",
            "Layer layer1.0.conv2 is quantized.\n",
            "Layer layer1.0.shortcut.0 is quantized.\n",
            "Layer layer1.1.conv1 is quantized.\n",
            "Layer layer1.1.conv2 is quantized.\n",
            "Layer layer1.2.conv1 is quantized.\n",
            "Layer layer1.2.conv2 is quantized.\n",
            "Layer layer1.3.conv1 is quantized.\n",
            "Layer layer1.3.conv2 is quantized.\n",
            "Layer layer2.0.conv1 is quantized.\n",
            "Layer layer2.0.conv2 is quantized.\n",
            "Layer layer2.0.shortcut.0 is quantized.\n",
            "Layer layer2.1.conv1 is quantized.\n",
            "Layer layer2.1.conv2 is quantized.\n",
            "Layer layer2.2.conv1 is quantized.\n",
            "Layer layer2.2.conv2 is quantized.\n",
            "Layer layer2.3.conv1 is quantized.\n",
            "Layer layer2.3.conv2 is quantized.\n",
            "Layer layer3.0.conv1 is quantized.\n",
            "Layer layer3.0.conv2 is quantized.\n",
            "Layer layer3.0.shortcut.0 is quantized.\n",
            "Layer layer3.1.conv1 is quantized.\n",
            "Layer layer3.1.conv2 is quantized.\n",
            "Layer layer3.2.conv1 is quantized.\n",
            "Layer layer3.2.conv2 is quantized.\n",
            "Layer layer3.3.conv1 is quantized.\n",
            "Layer layer3.3.conv2 is quantized.\n",
            "Layer linear is quantized.\n",
            "Number of quantized layers: 29\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "1-bit Quantized WRN_28_10_Relu6 model saved as WRN_28_10_Relu6_1bit.pth\n",
            "cp: target 'model' is not a directory\n",
            "copy 1bits model to google drive successfully!\n",
            "Creat WRN_quant successfully!\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Check if 2 bits model quantize successfully\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Layer conv1 is quantized.\n",
            "Layer layer1.0.conv1 is quantized.\n",
            "Layer layer1.0.conv2 is quantized.\n",
            "Layer layer1.0.shortcut.0 is quantized.\n",
            "Layer layer1.1.conv1 is quantized.\n",
            "Layer layer1.1.conv2 is quantized.\n",
            "Layer layer1.2.conv1 is quantized.\n",
            "Layer layer1.2.conv2 is quantized.\n",
            "Layer layer1.3.conv1 is quantized.\n",
            "Layer layer1.3.conv2 is quantized.\n",
            "Layer layer2.0.conv1 is quantized.\n",
            "Layer layer2.0.conv2 is quantized.\n",
            "Layer layer2.0.shortcut.0 is quantized.\n",
            "Layer layer2.1.conv1 is quantized.\n",
            "Layer layer2.1.conv2 is quantized.\n",
            "Layer layer2.2.conv1 is quantized.\n",
            "Layer layer2.2.conv2 is quantized.\n",
            "Layer layer2.3.conv1 is quantized.\n",
            "Layer layer2.3.conv2 is quantized.\n",
            "Layer layer3.0.conv1 is quantized.\n",
            "Layer layer3.0.conv2 is quantized.\n",
            "Layer layer3.0.shortcut.0 is quantized.\n",
            "Layer layer3.1.conv1 is quantized.\n",
            "Layer layer3.1.conv2 is quantized.\n",
            "Layer layer3.2.conv1 is quantized.\n",
            "Layer layer3.2.conv2 is quantized.\n",
            "Layer layer3.3.conv1 is quantized.\n",
            "Layer layer3.3.conv2 is quantized.\n",
            "Layer linear is quantized.\n",
            "Number of quantized layers: 29\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "2-bit Quantized WRN_28_10_Relu6 model saved as WRN_28_10_Relu6_2bit.pth\n",
            "cp: target 'model' is not a directory\n",
            "copy 2bits model to google drive successfully!\n",
            "Creat WRN_quant successfully!\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Check if 3 bits model quantize successfully\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Layer conv1 is quantized.\n",
            "Layer layer1.0.conv1 is quantized.\n",
            "Layer layer1.0.conv2 is quantized.\n",
            "Layer layer1.0.shortcut.0 is quantized.\n",
            "Layer layer1.1.conv1 is quantized.\n",
            "Layer layer1.1.conv2 is quantized.\n",
            "Layer layer1.2.conv1 is quantized.\n",
            "Layer layer1.2.conv2 is quantized.\n",
            "Layer layer1.3.conv1 is quantized.\n",
            "Layer layer1.3.conv2 is quantized.\n",
            "Layer layer2.0.conv1 is quantized.\n",
            "Layer layer2.0.conv2 is quantized.\n",
            "Layer layer2.0.shortcut.0 is quantized.\n",
            "Layer layer2.1.conv1 is quantized.\n",
            "Layer layer2.1.conv2 is quantized.\n",
            "Layer layer2.2.conv1 is quantized.\n",
            "Layer layer2.2.conv2 is quantized.\n",
            "Layer layer2.3.conv1 is quantized.\n",
            "Layer layer2.3.conv2 is quantized.\n",
            "Layer layer3.0.conv1 is quantized.\n",
            "Layer layer3.0.conv2 is quantized.\n",
            "Layer layer3.0.shortcut.0 is quantized.\n",
            "Layer layer3.1.conv1 is quantized.\n",
            "Layer layer3.1.conv2 is quantized.\n",
            "Layer layer3.2.conv1 is quantized.\n",
            "Layer layer3.2.conv2 is quantized.\n",
            "Layer layer3.3.conv1 is quantized.\n",
            "Layer layer3.3.conv2 is quantized.\n",
            "Layer linear is quantized.\n",
            "Number of quantized layers: 29\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "3-bit Quantized WRN_28_10_Relu6 model saved as WRN_28_10_Relu6_3bit.pth\n",
            "cp: target 'model' is not a directory\n",
            "copy 3bits model to google drive successfully!\n",
            "Creat WRN_quant successfully!\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Check if 4 bits model quantize successfully\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Layer conv1 is quantized.\n",
            "Layer layer1.0.conv1 is quantized.\n",
            "Layer layer1.0.conv2 is quantized.\n",
            "Layer layer1.0.shortcut.0 is quantized.\n",
            "Layer layer1.1.conv1 is quantized.\n",
            "Layer layer1.1.conv2 is quantized.\n",
            "Layer layer1.2.conv1 is quantized.\n",
            "Layer layer1.2.conv2 is quantized.\n",
            "Layer layer1.3.conv1 is quantized.\n",
            "Layer layer1.3.conv2 is quantized.\n",
            "Layer layer2.0.conv1 is quantized.\n",
            "Layer layer2.0.conv2 is quantized.\n",
            "Layer layer2.0.shortcut.0 is quantized.\n",
            "Layer layer2.1.conv1 is quantized.\n",
            "Layer layer2.1.conv2 is quantized.\n",
            "Layer layer2.2.conv1 is quantized.\n",
            "Layer layer2.2.conv2 is quantized.\n",
            "Layer layer2.3.conv1 is quantized.\n",
            "Layer layer2.3.conv2 is quantized.\n",
            "Layer layer3.0.conv1 is quantized.\n",
            "Layer layer3.0.conv2 is quantized.\n",
            "Layer layer3.0.shortcut.0 is quantized.\n",
            "Layer layer3.1.conv1 is quantized.\n",
            "Layer layer3.1.conv2 is quantized.\n",
            "Layer layer3.2.conv1 is quantized.\n",
            "Layer layer3.2.conv2 is quantized.\n",
            "Layer layer3.3.conv1 is quantized.\n",
            "Layer layer3.3.conv2 is quantized.\n",
            "Layer linear is quantized.\n",
            "Number of quantized layers: 29\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "4-bit Quantized WRN_28_10_Relu6 model saved as WRN_28_10_Relu6_4bit.pth\n",
            "cp: target 'model' is not a directory\n",
            "copy 4bits model to google drive successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.quantization import FakeQuantize, QConfig\n",
        "from torch.quantization import HistogramObserver\n",
        "from WRN_quant import Wide_ResNet as WRN_quant\n",
        "from Wide_Resnet import Wide_ResNet\n",
        "from torch.quantization import get_default_qconfig\n",
        "\n",
        "class CustomHistogramObserverActivation(HistogramObserver):\n",
        "    def __init__(self, num_bits, **kwargs):\n",
        "        self.num_bits = num_bits\n",
        "        super(CustomHistogramObserverActivation, self).__init__(**kwargs)\n",
        "\n",
        "    def calculate_qparams(self):\n",
        "        min_val, max_val = self.min_val, self.max_val\n",
        "        scale = (max_val - min_val) / (2 ** self.num_bits - 1)\n",
        "        zero_point = 0\n",
        "        return torch.tensor([scale]), torch.tensor([zero_point], dtype=torch.int64)\n",
        "\n",
        "\n",
        "class CustomHistogramObserverWeight(HistogramObserver):\n",
        "    def __init__(self, num_bits, **kwargs):\n",
        "        self.num_bits = num_bits\n",
        "        super(CustomHistogramObserverWeight, self).__init__(**kwargs)\n",
        "\n",
        "    def calculate_qparams(self):\n",
        "        min_val, max_val = self.min_val, self.max_val\n",
        "        scale = (max_val - min_val) / (2 ** self.num_bits - 1)\n",
        "        zero_point = int(-min_val / scale)\n",
        "        return torch.tensor([scale]), torch.tensor([zero_point], dtype=torch.int64)\n",
        "\n",
        "\n",
        "def custom_qconfig(num_bits):\n",
        "    return QConfig(\n",
        "        activation=FakeQuantize.with_args(observer=CustomHistogramObserverActivation, num_bits=num_bits,dtype=torch.quint8),\n",
        "        weight=FakeQuantize.with_args(observer=CustomHistogramObserverWeight, num_bits=num_bits, dtype=torch.qint8),\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    #训练参数\n",
        "    batch_size = 128\n",
        "    learning_rate = 0.1\n",
        "    epochs = 100\n",
        "    weight_decay = 0.0005\n",
        "    momentum = 0.9\n",
        "\n",
        "    #模型参数\n",
        "    depth = 28\n",
        "    widen_factor = 10\n",
        "    num_classes = 10\n",
        "    dropout_rate = 0.3\n",
        "\n",
        "    #量化范围\n",
        "    min_bits = 1 #最小为1\n",
        "    max_bits = 4 #最大为8\n",
        "\n",
        "    #设备设置\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Is GPU available?\", torch.cuda.is_available())\n",
        "    # 数据预处理\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # 加载CIFAR-10数据集\n",
        "    full_train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "    # 将训练数据集分为训练集、验证集和测试集\n",
        "    train_ratio = 0.7\n",
        "    validation_ratio = 0.1\n",
        "    test_ratio = 0.2\n",
        "    num_train_samples = int(len(full_train_dataset) * train_ratio)\n",
        "    num_validation_samples = int(len(full_train_dataset) * validation_ratio)\n",
        "    num_test_samples = len(full_train_dataset) - num_train_samples - num_validation_samples\n",
        "\n",
        "    train_dataset, validation_dataset, test_dataset_from_train = random_split(full_train_dataset, [num_train_samples, num_validation_samples, num_test_samples])\n",
        "    test_dataset = torch.utils.data.ConcatDataset([test_dataset, test_dataset_from_train])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # 创建Wide ResNet模型\n",
        "    model = Wide_ResNet(depth=depth, widen_factor=widen_factor, num_classes=num_classes, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "    # 设置损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "    # 设置学习率调度器\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120], gamma=0.1)\n",
        "\n",
        "    # 训练和测试函数\n",
        "    def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        return running_loss / len(dataloader)\n",
        "\n",
        "    def evaluate(model, dataloader, device):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "        return correct / total\n",
        "\n",
        "    #量化前评估函数\n",
        "    def calibrate(model, loader, device,):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, _ in loader:\n",
        "                images = images.to(device)\n",
        "                _ = model(images)\n",
        "    \n",
        "    #量化后检查函数\n",
        "    def check_quantization_after_convert(model):\n",
        "        quantized_layers = 0\n",
        "        for layer_name, layer in model.named_modules():\n",
        "            if isinstance(layer, (nn.quantized.Conv2d, nn.quantized.Linear)):\n",
        "                quantized_layers += 1\n",
        "                print(f\"Layer {layer_name} is quantized.\")\n",
        "            elif isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "                print(f\"Layer {layer_name} is not quantized.\")\n",
        "        return quantized_layers\n",
        "\n",
        "    #以num_bits量化并保存模型函数\n",
        "    def quantize_num_bits_model(o_model, num_bits, device, depth, widen_factor, num_classes, dropout_rate, validation_loader, test_loader):\n",
        "        model = WRN_quant(depth=depth, widen_factor=widen_factor, num_classes=num_classes, dropout_rate=dropout_rate).to(device)\n",
        "        model.load_state_dict(o_model.state_dict())\n",
        "        model.eval()\n",
        "\n",
        "        if num_bits == 8:\n",
        "            model.qconfig = get_default_qconfig('fbgemm')\n",
        "        else:\n",
        "            model.qconfig = custom_qconfig(num_bits)\n",
        "        torch.quantization.prepare(model, inplace=True)\n",
        "        calibrate(model, validation_loader, device)\n",
        "        model.to('cpu')\n",
        "        torch.quantization.convert(model, inplace=True)\n",
        "\n",
        "        # 在量化后检查实际量化的层数\n",
        "        separator = '- ' * 25\n",
        "        print(separator)\n",
        "        print(separator)\n",
        "        print(f\"Check if {num_bits} bits model quantize successfully\")\n",
        "        print(separator)\n",
        "        quantized_layers = check_quantization_after_convert(model)\n",
        "        print(f\"Number of quantized layers: {quantized_layers}\")\n",
        "        print(separator)\n",
        "        print(separator)\n",
        "\n",
        "        # 保存量化模型\n",
        "        quantized_model_path = f\"WRN_{depth}_{widen_factor}_Relu6_{num_bits}bit.pth\"\n",
        "        torch.save(model.state_dict(), quantized_model_path)\n",
        "        print(f\"{num_bits}-bit Quantized WRN_{depth}_{widen_factor}_Relu6 model saved as {quantized_model_path}\")\n",
        "\n",
        "\n",
        "        #在测试集上评估量化模型\n",
        "        quantized_accuracy = evaluate(model, test_loader, 'cpu')\n",
        "        print(f\"Quantized test accuracy: {quantized_accuracy * 100:.2f}%\")\n",
        "        return\n",
        "    # 训练循环\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        validation_accuracy = evaluate(model, validation_loader, device)\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch: {epoch}, Loss: {train_loss:.4f}, Validation Accuracy: {validation_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 在测试集上进行评估全精度模型\n",
        "    test_accuracy = evaluate(model, validation_loader,  device)\n",
        "    print(f\"full_precision model Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 保存全精度模型\n",
        "    model_path = f\"WRN_{depth}_{widen_factor}_Relu6_full_precision.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"full_precision WRN_{depth}_{widen_factor}_Relu6 model saved as WRN_full_precision.pth\")\n",
        "    !cp /content/{model_path} /content/drive/MyDrive/model\n",
        "    print(f'copy full_precision model to google drive successfully!')\n",
        "\n",
        "    #获得从min_bits到max_bits量化的模型\n",
        "    for num_bits in range(min_bits, max_bits+1):\n",
        "        quantize_num_bits_model(model, num_bits, device, depth, widen_factor, num_classes, dropout_rate, validation_loader, test_loader)\n",
        "        !cp /content/{quantized_model_path} /content/drive/MyDrive/model\n",
        "        print(f'copy {num_bits}bits model to google drive successfully!')\n",
        "\n",
        "\n",
        "    # temp = model.state_dict()\n",
        "    # model = WRN_quant(depth=16, widen_factor=8, num_classes=10, dropout_rate=0.3)\n",
        "    # model.load_state_dict(temp)\n",
        "    # model.to('cpu')\n",
        "    # model.eval()\n",
        "    # model_fused = model\n",
        "    # model_fused = QuantizedNet(model_fp32=model)\n",
        "    # model.qconfig = custom_qconfig(7)\n",
        "    #\n",
        "    # torch.quantization.prepare(model, inplace=True)\n",
        "    #\n",
        "    # def calibrate(model, loader, device):\n",
        "    #     model.eval()\n",
        "    #     with torch.no_grad():\n",
        "    #         for images, _ in loader:\n",
        "    #             images = images.to(device)\n",
        "    #             _ = model(images)\n",
        "\n",
        "    # calibrate(model, train_loader, 'cpu')\n",
        "    # print(model.qconfig)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # torch.quantization.convert(model, inplace=True)\n",
        "    # print(model.state_dict())\n",
        "    # def check_quantization_after_convert(model):\n",
        "    #     quantized_layers = 0\n",
        "    #     for layer_name, layer in model.named_modules():\n",
        "    #         if isinstance(layer, (nn.quantized.Conv2d, nn.quantized.Linear)):\n",
        "    #             quantized_layers += 1\n",
        "    #             print(f\"Layer {layer_name} is quantized.\")\n",
        "    #         elif isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "    #             print(f\"Layer {layer_name} is not quantized.\")\n",
        "    #     return quantized_layers\n",
        "    #\n",
        "    # def quantize_num_bits_model(model, num_bits):\n",
        "    #\n",
        "    #     return\n",
        "    # # 在量化后检查实际量化的层数\n",
        "    # quantized_layers = check_quantization_after_convert(model)\n",
        "    # print(f\"Number of quantized layers: {quantized_layers}\")\n",
        "    # quantized_accuracy = evaluate(model, train_loader, 'cpu')\n",
        "    # print(f\"Quantized test accuracy: {quantized_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # print(model.conv1.scale, model.conv1.zero_point)\n",
        "\n",
        "    # print(model_fused.layer1.scale, model_fused.layer1.zero_point)\n",
        "    # print(model_fused.layer2.scale, model_fused.layer2.zero_point)\n",
        "    # print(model_fused.bn1.scale, model_fused.bn1.zero_point)\n",
        "    # def check_quantization_after_convert(model):\n",
        "    #     quantized_layers = 0\n",
        "    #     for layer_name, layer in model.named_modules():\n",
        "    #         if isinstance(layer, (nn.quantized.Conv2d, nn.quantized.Linear)):\n",
        "    #             quantized_layers += 1\n",
        "    #             print(f\"Layer {layer_name} is quantized.\")\n",
        "    #         elif isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "    #             print(f\"Layer {layer_name} is not quantized.\")\n",
        "    #     return quantized_layers\n",
        "    #\n",
        "    # # 在量化后检查实际量化的层数\n",
        "    # quantized_layers = check_quantization_after_convert(model)\n",
        "    # print(f\"Number of quantized layers: {quantized_layers}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    !cp /content/WRN_28_10_Relu6_full_precision.pth /content/drive/MyDrive/model"
      ],
      "metadata": {
        "id": "393gD9c_VZEy"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}